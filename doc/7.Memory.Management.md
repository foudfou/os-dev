# 7 Memory Management

Our next big ambition is enable paging. Actually what we want is actually
**virtual memory**. On x86, there are 2 ways to achieve this: **segmentation**
or **pagination**.

Before we dive into these concept, why virtual memory ?

> Because virtual memory reduces the complexity of programming, by giving each
> program an illusion that it has its own separate "physical" memory to work
> with. Without virtual memory, programs must know and agree with each other
> their own memory regions to not accidentally destroy each other. [^os0to1]

That's the first reason: usability. The other reasons are tight to memory
management in general:

> One of the major reponsibilities of an OS kernel is to provide memory
> abstraction for user programs. Such abstraction should also guarantee at
> least the following two properties:
>
> - *Access control*: allow us to describe specific permissions on different
>   regions of the memory space
> - *Isolation*: memory operations issued by one process should not directly
>   interfere with other processes (and the kernel, obviously) [^hux-kernel]

By the way there are 2 address spaces, one for memory and one for I/O, with
distinct hardware buses.

## Segmentation

We've encountered segmentation when switching to protected mode where we chose
to use flat memory model, as opposed to "multi-segment model" for
example. Remember segmentation, introduced on the 8086 in 1978, was first
intended to allow addressing more than 64 KiB of memory.

> The Intel 80286 introduced a second version of segmentation in 1982 that
> added support for virtual memory and memory protection. At this point the
> original model was renamed *real mode*, and the new version was named
> *protected mode*. [^wikipedia]

OsDev wiki has this warning:

> Segmentation is considered obsolete memory protection technique in protected
> mode by both CPU manufacturers and most of programmers. It is no longer
> supported in long mode [^osdev].

Note segmentation can technically be used in conjunction with paging. For both
address translation happens with the help of a hardware chip:

> A hardware memory management unit (MMU) is responsible for translating the
> segment and offset into a physical address, and for performing checks to make
> sure the translation can be done and that the reference to that segment and
> offset is permitted. [^wikipedia]

Segmentation allows for allocating memory in chunks of varying and meaningful
sizes, selected by the compiler.

Conceptually the mapping from logical to physical address is stored into a
**segment table** [^ucsd], with one entry per segment. On x86, this is achieved
via the GDT and LDT (Local Descriptor Table). Each process can have it's own
segment table to enjoy its own virtual address space.

> The processor will automatically switch to the right LDT when you use
> hardware task switching [^osdev-gdt]

Since segments vary in size, direct segmentation leads to [*external
fragmentation*](https://github.com/josehu07/hux-kernel.wiki/blob/master/09.-Intro-to-Virtual-Memory.md),
where space between segments can't be used.

## Pagination

With pagination we divide memory spaces into fixed-sized chunks, usually 4 KiB,
called **pages**:

- the physical memory is divided into fixed-sized chunks called **frames**,
  also sometimes referred to as "physical pages".
- the virtual memory for user processes is are also divided into fixed-sized
  chunks of the same size called **pages**

For each user process, we keep a *page table* somewhere in kernel memory to map
logical addresses to physical addresses.

> Though paging solves the problem of external fragmentation, it actually makes
> *internal fragmentation* worse - user processes that do not need a full 4 KiB
> slot of memory have to occupy a whole 4 KiB slot.
>
> Nevertheless, having internal fragments is still better than having external
> fragments, as they do not require a dedicated cleaner and are more
> predictable (half a page per allocation in average). [^hux-kernel]

> On x86, the physical address of the current active process's page table is
> stored in control register `CR3`. Our OS is responsible for loading and
> updating this register correctly. Page table format is specified by hardware
> architectural-level specification. Translation is done entirely by the CPU in
> hardware. [^hux-kernel]

## Implementation

As expressed by others, for instance [the author of
Osdev-Notes](https://www.reddit.com/r/osdev/comments/ve7kyl/comment/icw2dsu/),
memory management is a bit of an involved topic as we need to understand
multiple parts and how they fit into the big picture.

At high level, we'd like to efficiently allocate bits of memory. This will
involve roughly 3 layers [^Osdev-Notes]:

- **Physical memory manager** (PMM): tracks free/used frames.
- **Paging**: effectively enables *virtual memory* and *virtual addresses* via
  (virtual) pages, providing the OS with a bigger address space, data and code
  protection, and isolation between programs. Note for a lot of projects,
  paging and the **virtual memory manager** (VMM) will be the same
  thing. However paging is just one tool for the VMM. It can use paging or
  segmentation or swapping (one process requesting pages from others), or a
  combination of all these.
- **Heap Allocator**: The VMM can handle page-sized allocations just fine, but
  that is not always useful. A heap allocator allows for allocations of any
  size, big or small, be it by splitting or aggregating pages.

While there is only a single PMM per running OS, which manages all of the
available memory, there is
- one VMM per process. When using a higher half kernel, the upper half of every
  VMM will be identical and contain the protected kernel code and data.
- at last one heap allocator per process. It can exist in kernel or user space.

Common and simple implementations include:
- a bitmap for PMM
- a doubly linked list for the heap allocator

Putting it togeter, considering a setup with paging enabled, when a user
process does `alloc(5)`, what happens effectively is:

1. The allocation request asks the heap allocator for an area of 5 bytes.
2. The heap allocator searches for a region big enough for 5 bytes. If
   available in the current heap, it returns a pointer to it. Otherwise, it
   will ask the VMM for more space. Remember: the *addresses returned by the
   heap allocator are virtual*.
3. The VMM will ask the PMM for a new physical page.
4. The PMM allocates a new physical page, which will be mapped to the VMM. Now
   the VMM will provide the heap with the extra space it needed, and the heap
   can return an address using this new space.


## References

- [^osdev-notes]: [Osdev-Notes](https://github.com/dreamos82/Osdev-Notes/blob/master/02_Memory_Management/01_README.md)
- [^osdev-gdt]: [Osdev-GDT](https://wiki.osdev.org/GDT_Tutorial#The_LDT)
- [^hux-kernel]: [hux-kernel](https://github.com/josehu07/hux-kernel)
- [^os0to1]: [os0to1](https://github.com/tuhdo/os01/)
- [^wikipedia]: [wikipedia](https://en.wikipedia.org/wiki/X86_memory_segmentation)
- [^ucsd]: [ucsd](https://cseweb.ucsd.edu/classes/sp17/cse120-a/applications/ln/lecture11and12.html)
