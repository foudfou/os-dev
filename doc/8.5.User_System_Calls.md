# 8.5 User System Calls

**Note**: this iteration is captured in the git tag `syscalls`.

At this point it'd be nice if init could spawn a shell. This would require us
implementing at least a shell, process management functions (like `exec()`,
`fork()`, `wait()`), and possibly a minimal filesystem for standard input and
outputâ€¦ We may also want to load this shell from a filesystem and add
pre-emptive scheduling to orchestrate processes launched by the shell.

But there is actually a more immediate matter that needs our attention: provide
a user API so users can program for our OS and we can write user
programs. Starting withâ€¦ a use-space `init`! So how about we focus on this
small step: having a user-space init process that prints something and exits?

Note this defeats the purpose of `init` which should never exit until the
system shuts down and remains the parent of all processes. But we'll fix that
later.

And before looking at the `exit()` system call, we need to tidy up our syscall API.

## Syscall API

For user processes to properly do system calls, we need a couple additions:

1. allow programs to pass arguments to system calls.
1. a user interface to expose syscalls.

To validate this API end-to-end, we will replace our `initcode.asm` with a user
`init.c`, same as hux-kernel or xv6. Init will call our previously implemented
dummy `hello()` syscall and the newly provided `exit()`.

### Syscall calling convention

We will adopt the **C calling convention**[^freebsd] which is passing the
syscall number in EAX, arguments on the stack, in reverse order, preceded by
EIP.

Note this is unsurprisingly what compiled C programs do: they `push` arguments
in reverse order and call the function with the assembly `call` operation,
which itself `push`es EIP onto the stack. This is particularly relevant if we
call system calls in user assembly programs:

> it is assumed the program will call a function that issues `int 80h` [^freebsd]

This is all great but, on the other side of things, how can the kernel access
the process stack? In other words how can system calls access user space?

There are a couple of important aspects related to the switch back to ring-0.

For one, while the syscall handler is running in kernel mode, **from the CPU
point of view, the currently running process still is the user process**. In
particular the cpu still uses the process memory mapping. Meaning the kernel
can directly access the process user space in low virtual memory!

Next, the **cpu now uses the process kernel stack** since we switched back to
the kernel context during the interrupt. Meaning that the process kernel stack
remained untouched while we were in user mode.

Quick recap of what happened is:

- ring-0 â†’ ring-3: `swtch()` and `iret` â‡’ trap frame popped from the stack;
- `init` runs in ring-3 and triggers a trap;
- cpu immediately switches back to ring-0, with ESP now pointing to `ts.esp0`,
- cpu executes `isr_wrapper` which pushes a new trap frame to the stack.

Thus, at the point of executing the syscall, ESP points to the same location
`p->tf` was pointing before the switch to ring-3.

Now the kernel can derive the process user stack from multiple sources: the
handler interrupt state (`struct interrupt_state`) or the trap frame of the
current process structure (`p->tf->esp`), which both point to the same memory
location.

Actually, since the syscall handler is the first thing being called when
switching to ring-0, there shouldn't be any situation where the new trap frame
would not be at the same memory location than when we initiated the switch to
ring-3. And so xv6's `myproc()->tf = tf` in the syscall trap handler isn't
strictly necessary.

What happens when the syscall completes? How does the process return to ring-3?
Well, like for all interrupts, `isr_wrapper` resumes after `isr_handler`
returns and restores the user process context (`trapret`), goes through `iret`,
which uses the restored code segment (DPL=3), thus returning to ring-3.

Note different OSes and ABIs adopt a different calling conventions:

- on x86_64 parameters are passed via registers rdi, rsi, rdx, rcx, r8, r9, and
  further values are passed on the stack in reverse order. Using registers is
  generally faster as it reduces the number of memory accesses.
- SOS[^sos] passes arguments via registers (eax=syscall_id, ebx=arg1, ecx,
  edx), also passing the trap frame `struct sos_cpu_state` down to syscall
  implementations.
- 386BSD fetches arguments from the stack, the stack pointer being retrieved
  from the trap frame.

The benefit of `myproc()->tf->esp` to fetch syscall arguments over using the
received `struct interrupt_state` is that we start by identifying the the
current process (`myproc()`), which enables us to do sanity checks on the
syscall arguments: for example that the process accesses memory within its
allowed boundaries (`curproc->sz`) or that a string is null-terminated within
the process boundaries. The downside is that, with xv6's implementation,
fetching multiple arguments incurs repeated calls to `myproc()` and thus a lot
of not-so-necessary `pushcli()`/`popcli()` cycles.

Making sure syscall arguments point to user memory is critical: syscalls run in
ring-0 and can thus access kernel memory which we don't want to leak.

> if a user program tries to read or write memory at an address of `p->sz` or
> above, the processor will cause a segmentation trap, and trap will kill the
> process, as we saw above. The kernel, however, can de-reference any address
> that the user might have passed, so it must check explicitly that the address
> is below p->sz. [^xv6-book]

Right, so having to get characteristics about the current process anyways,
let's read the stack pointer from `tf->esp` (this is also what xv6 does) and do
pointer arithmetic to fetch arguments. These are the utility functions in
`syscall.c` for syscall implementations to extract arguments from the stack
(`sysarg_get_int()` for an `int` for example).

It will be the responsibility of the syscall implementations `SYS_*` to validate
and sanitize user input. Real world OSes go to great lengths to handle system
call parameters accurately and securely. Especially pointers:

> Since system calls are executed in kernel mode, they have access to kernel
> space and if pointers are not properly checked user applications might get
> read or write access to kernel space. [^linux-labs]


### Interlude â€” bootloader limitation

Our kernel grew to the point that it doesn't fit the buffer we use in `stage2`
(50 sectors) ðŸ˜¡

To overcome this issue (again), we simply use a bigger temporary buffer located
a bit higher in memory: above our bootloader but under EBDA (Extended BIOS Data
Area). We're still pulling in one single chunk for simplicity.

Quick recap on what happens in our bootloader during the boot process:

- BIOS loads first sector from first bootable device (`stage1`) into memory
  0x7C00 and jumps to it. We are in 16-bit real mode.
- `stage1` loads `stage2` (2 sectors) from the floppy into 0x7E00 and jumps
  to it.
- `stage2`:
  - reads the e820 memory map from the BIOS and writes it to 0xA000;
  - loads the kernel (72 sectors) from the floppy into a temporary buffer at 0x20000;
  - copies from the buffer to extended memory 0x100000;
  - activates A20-Gate;
  - switches to 32-bit protected mode, setting the stack pointer to 0x90000;
  - jumps to the kernel at 0x100000.
- [`kernel_entry` enables paging (higher-half kernel) and sets up a new 16K
  stack located at its end, before jumping to the kernel `main`.]

Ultimately, the bootloader uses this memory range:

```
BIOS-e820: [base=0x0000000000000000 length=0x000000000009f000] type=1 (free)
```

The updated memory layout looks like:

| Address                 | Stuff                             |
|----------------------|-----------------------------------|
| ~~0x1000~~           | ~~4. buffer to load kernel~~      |
| ~~0x5000 (512*40)~~  | ~~4. buffer end~~                 |
| 0x7c00               | 1. bootloader stage1              |
| 0x7e00               | 2. bootloader stage2              |
| 0x81ff               | 2. bootloader stage2 end          |
| 0xA000               | 3. `E820_MAP` memory map          |
| **0x20000**          | **4. buffer to load kernel**      |
| **0x29000 (512*72)** | **4. buffer end**                 |
| 0x90000              | 5. Stack end after protected mode |
| 0x9f000              | end of first memory region        |
| â€¦                    | â€¦                                 |
| 0x100000             | 6. kernel start                   |

This quick fix will leave us some room, but next time, we may have to copy in
multiple chunks. Maybe another solution would be to load from the hard drive
(intÂ 0x13/ah=0x42), which would allow us a limit of 127 sectors. We will indeed
want to use a hard drive at some point for the file system.

This change has some impact implementation-wise:

- Since we changed the memory destination for kernel code from 0x1000 to
  0x20000, we need to adapt parameters to `disk_load`. This routing uses
  INTÂ 13hÂ AH=02h which awaits the destination in ES:BX. BX alone can't hold our
  value anymore and we need to break it down into ES=0x2 and BX=0x0.
- We take the opportunity to extract constants to `_defs.asm` files which we
  auto-translate during the build to `_defs.h` C headers thus effectively
  sharing variables between assembly and C! Note this would be trivial if
  assembly files were compiled with gcc: the preprocessor would resolve
  `#include`s, `#define`s and the like.

### Syscall user interface

To expose our kernel system calls to user programs, we need:

1. `user.h`: a header file with the system call signatures;
2. `syscall.o` (result of `syscall.asm`): syscall wrappers, counterparts of the
   kernel syscalls. For example, when a user program calls `exit()`, it
   doesn't call the kernel implementation `sys_exit()` directly. As per our C
   calling convention, the user function `exit()` is a wrapper that issues the
   `IDT_TRAP_SYSCALL` interruption (0x40) with the related syscall number
   `SYS_exit`.

Note some system support multiple calling convention (see SOS[^sos] in
`_sos_syscall3()` for instance). But we don't need that.

Here is a summary of the relevant files:

```
â”œâ”€â”€ kernel
â”‚Â Â  â”œâ”€â”€ â€¦
â”‚Â Â  â”œâ”€â”€ syscall.c   # handler and argument utilities
â”‚Â Â  â”œâ”€â”€ syscall.h
â”‚Â Â  â”œâ”€â”€ syshello.c  # syscall implementation for hello()
â”‚Â Â  â”œâ”€â”€ sysproc.c   # syscall implementation for exit()
â”‚â€¦
â””â”€â”€ user
    â”œâ”€â”€ â€¦
    â”œâ”€â”€ init.c
    â”œâ”€â”€ syscall.asm  # syscall wrappers
    â””â”€â”€ user.h       # syscall signatures
```

## Exit

The syscall `sys_exit()` only calls kernel `exit()` which in turn only marks
the process as a `ZOMBIE` and *yields* control to the scheduler.

We're tempted to release the memory used by finished `init` process. But that's
meant to be `wait()`'s job: a parent is responsible for cleaning up its
children. `init` will thus `wait()` for it's children when we have implemented
`exec()`, `fork()` and `wait()`.

So there's not much more to do at this point.

## C init

Our `init` program can issue system calls with provided interfaces:

1. `#include "user/user.h"`
2. link against: `user/syscall.o`

The Makefile to compile `init` is adapted accordingly.

Additionally we need to adapt `init`'s compilation with `-fno-stack-protector`
and either one of `-maccumulate-outgoing-args` or
`-mpreferred-stack-boundary=2`. That's because the default code generated by
the compiler (gcc-12.2) for `-fstack-protector` and stack alignment targets
memory outside the process boundaries (`0x1000` and above).

Especially, right at the beginning of `init.out` we get:

```
   0:   8d 4c 24 04             lea    0x4(%esp),%ecx
   4:   83 e4 f0                and    $0xfffffff0,%esp
   7:   ff 71 fc                push   -0x4(%ecx)
```

LEA is "load effective address" which only performs memory calculation but does
not actually address memory, i.e. doesn't do indirect memory access. Here, ESP
starting with 0x1000, line 0 will set ECX to 0x1004.

Then the stack is aligned to a 16-byte boundary on line 4.

Then line 7 saves the contents of the address at ECX - 4, that is 0x1000, to
the stack. This is where the program attempts to access memory at 0x1000 which
is not allowed by our virtual memory mapping.

The purpose of line 7 is to make sure the return address of the caller is
preserved[^SO]. But our `init` hasn't got any C caller.

We also take the opportunity to move all kernel code (`drivers/` and `lib/`) to
the `kernel/` folder to further distinguish kernel from user code. A convention
xv6 adopted in xv6-riscv.

## Scheduler

At this stage, it's fine completing the scheduler loop with the missing code
from xv6. Adding `switchkvm()` especially completes the yield process by
switching to the kernel page table.

Looking further at the scheduler, there is an unusual handling of the process
table lock: in the scheduler loop, we acquire it to find a runnable process,
but we run the process immediately, instead of releasing the lock. From xv6's
code:

```C
      // [â€¦] It is the process's job
      // to release ptable.lock and then reacquire it
      // before jumping back to us
```

To understand why, let's follow the lock acquisitions and releases:

```
scheduler:
â€¦
    acquire(&ptable.lock);
    for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
â€¦
      swtch(&(c->scheduler), p->context);  // ===> enter_process
      switchkvm();  // <=== back from process later
â€¦
    }
    release(&ptable.lock);

enter_process:
â€¦
  release(&ptable.lock);

exit:
â€¦
  acquire(&ptable.lock);
â€¦
  enter_scheduler();

enter_scheduler: [sched() in xv6]
  if(!holding(&ptable.lock))
    panic("sched ptable.lock");
â€¦
  swtch(&p->context, mycpu()->scheduler);  // ===> scheduler loop
```

According to the previously mentioned comment:

- the kernel acquires the lock before scheduling a process;
- the process immediately releases and executes;
- when given back control, for example via a syscall like `exit()`, the kernel re-acquires;
- the kernel releases almost immediately, namely after resetting the page directory.

> xv6 holds `ptable.lock` across calls to swtch: the caller of `swtch` must
> already hold the lock, and control of the lock passes to the switched-to
> code. This convention is unusual with locks; usually the thread that acquires
> a lock is also responsible for releasing the lock, which makes it easier to
> reason about correctness. For context switching it is necessary to break this
> convention because `ptable.lock` protects invariants on the processâ€™s `state`
> and `context` fields that are not true while executing in `swtch`. One
> example of a problem that could arise if `ptable.lock` were not held during
> `swtch`: a different CPU might decide to run the process after `yield` had
> set its state to RUNNABLE, but before `swtch` caused it to stop using its own
> kernel stack. The result would be two CPUs running on the same stack, which
> cannot be right. [^xv6-book]

To understand what these exact invariants are, let's look at what changes
during context switches:

- from kernel to process: `p->state`, `cpu->scheduler` (`structÂ context`) are
  updated.
- from process to kernel: `p->xstate` (exit status), `p->state`, `p->context`
  are updated.

What this means is that we want to treat process scheduling and yielding as
critical sections and avoid situations where process information is
inconsistent, which could lead for example to another CPU scheduling an
unsuitable process. Remember also that acquiring a lock disables interrupts.

It's important to note that, once a process is scheduled and until it's
finished, `swtch()` calls always resume to the next line in the C source file:
this is not dead code! So that execution basically alternates between 2
`swtch()` calls: inside `scheduler()` and inside `enter_scheduler()` (xv6
`sched()`). This is also known as *coroutines*, a [term coined by
Conway](https://en.wikipedia.org/wiki/Coroutine) in 1958, the one gave his name
to the famous law:

> "Organizations, who design systems, are constrained to produce designs which
> are copies of the communication structures of these organizations."

Not to be confused with the Conway who devised the well-known [game of
life](https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life).

## References

- [^freebsd]: [freebsd](https://docs.freebsd.org/en/books/developers-handbook/x86/#x86-system-calls)
- [^linux-labs]: [linux-labs](https://linux-kernel-labs.github.io/refs/heads/master/lectures/syscalls.html#system-call-parameters-handling)
- [^sos]: [sos](sos.enix.org/)
- [^xv6-book]: [xv6-book](https://pdos.csail.mit.edu/6.828/2018/xv6/book-rev11.pdf)
- [^SO]: [SO](https://reverseengineering.stackexchange.com/a/18969)
