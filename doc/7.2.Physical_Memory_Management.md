# 7.2 Physical Memory Management

Understanding and managing physical memory is key to enable virtual memory.

On bochs or qemu, a [typical memory
map](https://wiki.osdev.org/Memory_Map_(x86)#Overview) looks like this:

```
BIOS-e820: [base=0x0000000000000000 length=0x000000000009f000] type=1 (free)
BIOS-e820: [base=0x000000000009f000 length=0x0000000000001000] type=2 (reserved)
BIOS-e820: [base=0x00000000000e8000 length=0x0000000000018000] type=2 (reserved)
BIOS-e820: [base=0x0000000000100000 length=0x0000000007ef0000] type=1 (free)
BIOS-e820: [base=0x0000000007ff0000 length=0x0000000000010000] type=3 (acpi)
BIOS-e820: [base=0x00000000fffc0000 length=0x0000000000040000] type=2 (reserved)
```

Remember the kernel gets this list from our bootloader. Ideally we would clean
up that list:

> After getting the list, it may be desirable to: sort the list, combine
> adjacent ranges of the same type, change any overlapping areas to the most
> restrictive type, and change any unrecognised "type" values to type 2. [^osdev]

See for example [the linux for cleaning up the memory
map](https://github.com/torvalds/linux/blob/f0e18b03fcafd8344539101f564ae358950ae892/arch/x86/kernel/e820.c#L83)

Note also the acpi region is reclaimable, i.e. it can be considered free, as
long as we don't need the ACPI tables stored there.

But for simplicity, we'll only use one memory region: the *extended memory*
starting at 1MB (0x100000).

Our kernel is initially loaded to memory address 0x1000, then copied to high
memory 0x100000. The reasons we do that are: 1. easier paging mapping as the
kernel space, code and data, is located in one chunk in a clear location, 2. we
have to worry less about constrained space if our kernel grows in size.

For now, our bootloader loads the kernel in a single chunk of maximum 512\*40
bytes, 40 being the number of sectors loaded from disk. Note we currently can't
load much more than 40 sectors without risking to override our boot_sect code
in memory: 0x1000+(512\*40)=0x6000, 0x1000+(512\*60)=0x8800. So if our kernel
grows beyond 40 sectors, we'll just have to copy it chunk by chunk.

The kernel will also need to know its size so it knows what portions of memory
it can use, for exaple to store its data. We could get the size of our kernel
from a bootloader like GRUB. Note also that, GRUB being able to load ELF
binaries, it projects them to the address set by the linker, which typically is
to extended memory (> 1 MiB) [^sos] [^hux-kernel]. But what we do instead is
track the offsets of our kernel start and end in our LD script
`kernel.lds` [^nullprog]:

```
/* kernel.lds */
    . = 0x100000;
    __k_start = .;

/* in C code */
extern char __k_start, __k_end; // use &__k_end !!
```

At this stage, we need to decide how we're going to organize memory for:

- our kernel's own usage, for example to track memory usage → kernel-reserved
  "kernel heap"
- free memory for paging, for user processes

It's not unusual that OSes choose to put paging information, like the frame
bitmap or the page descriptor array, after the end of the loaded kernel.

We'll also follow that design and our memory will look like this:

| Addr            | Stuff                                                                             |
|-----------------|-----------------------------------------------------------------------------------|
|                 |                                                                                   |
| 0x1000          | 4. `KERNEL_OFFSET1`, stage2 buffer start to copy kernel to high memory            |
|                 |                                                                                   |
| 0x5000 (512*40) | 4. stage2 buffer end                                                              |
|                 |                                                                                   |
| 0x7c00          | 1. bootloader stage1, can be overriden by kernel. Stack end before protected mode |
|                 |                                                                                   |
| 0x7e00          | 2. bootloader stage2, can be overriden by kernel                                  |
|                 |                                                                                   |
| 0x81ff          | 2. bootloader stage2 end                                                          |
|                 |                                                                                   |
| 0xA000          | 3. `MEM_MAP` memory map                                                           |
|                 |                                                                                   |
| 0x90000         | 5. Stack end after protected mode                                                 |
|                 |                                                                                   |
| 0x9f000         | end of first memory region                                                        |
|                 |                                                                                   |
| 0x100000        | 6. `KERNEL_OFFSET2`, `__kstart` kernel start                                      |
|                 |                                                                                   |
| ???             | 6. `__kend` kernel end                                                            |
|                 |                                                                                   |
| ??? (0x105000)  | 6. `kheap_curr` start of kernel heap                                              |
|                 |                                                                                   |
| 0x800000        | 6. `KHEAP_MAX_ADDR`                                                               |
|                 |                                                                                   |

Again, it is critical to understand the physical memory layout, during and
after the bootloader process, as it's easy to make mistakes in design choices
that lead to various hard-to-debug issues, like not loading enough of the
bootloader or the kernel, overriding code region while loading, stack clashing
with kernel code, etc.

## Frame map

The duties of physical memory manager will be: 1. keep track of allocated
frames, 2. allocate chunks of physical memory of arbitrary size for kernel use.

For example we'll use a bitmap to store frame allocation. But we don't know the
size of the memory before booting so we'll need to dynamically allocate space
for our frame bitmap.

For the bitmap implementation we'll shamelessly just use one from
[Stackoverflow](https://stackoverflow.com/a/24753227/421846). One optimization,
that we won't implement, that would speed up lookups from O(n) to O(1), would
be to keep track of the last place free space we found.

For the kernel allocator, we can start with a so-called *bump allocator*, aka
[WaterMark allocator](https://wiki.osdev.org/Memory_Allocation#A_very_very_simple_Memory_Manager),
which only grows, as

> everything we need to allocate [to setup paging] will never be freed because
> they are data structures that must exist throughout the kernel's
> lifetime [^hux-kernel]

We'll follow Hux's path later and implement a proper heap allocator for our
kernel using a doubly-linked list.

Other projects have different approaches for frame allocation:

- [Hux uses a slab
  allocator](https://github.com/josehu07/hux-kernel.wiki/blob/master/12.-Aligned-SLAB-Allocators.md)
  for frame allocation. More on SLAB allocation in a moment
- sos [^sos] starts straightaway with two doubly-linked lists: free and used
  frames.
- xv6 only uses fixed page-size allocation and uses a linked list for free
  pages threaded through the pages themselves. Note this is slab allocation.
  It also uses a separate page allocator during entry, which does not support
  freeing.

## Slab allocation

Similar to object pools but applied to memory:

> When the allocator is asked to free the object's memory, it just adds the
> slot to the containing slab's list of free (unused) slots [rather than doing
> the work of destroying it]. The next call to create an object of the same
> type (or allocate memory of the same size) will return that memory slot (or
> some other free slot) and remove it from the list of free slots. [^wikipedia]

Can be used in other contexts like inodes.

*Segregated list* is the parent concept. Slab allocateor is a specialization in
that is keeps free objects on the lists in a pre-initialized state.


## References

- [^sos]: [sos](sos.enix.org/)
- [^hux-kernel]: [hux-kernel](https://github.com/josehu07/hux-kernel)
- [^nullprog]: We're very greatful to Chris Wellons for his amazing blog post
  on [How to build DOS COM files with
  GCC](https://nullprogram.com/blog/2014/12/09/) which made it explicit that we
  need to use the *address* of the linker variable!
- [^wikipedia]: [wikipedia](https://en.wikipedia.org/wiki/Slab_allocation)
